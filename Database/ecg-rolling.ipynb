{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import posixpath\n",
    "import wfdb\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs: https://wfdb.readthedocs.io/en/latest/wfdb.html\n",
    "# SpO2が含まれているデータは a01r のようにrが付いている\n",
    "# records\n",
    "\n",
    "# 'a01r', 'a02r', 'a03r', 'a04r', 'b01r', 'c01r', 'c02r', 'c03r'\n",
    "subjects = ['a01r', 'a02r', 'a03r', 'a04r', 'b01r', 'c01r', 'c02r', 'c03r']\n",
    "records = {}\n",
    "\n",
    "# データの読み込み\n",
    "for subject in subjects:\n",
    "    path = \"dataset/\" + subject\n",
    "    records[subject] = wfdb.rdrecord(path)  # 計測データ\n",
    "    records['ann_' + subject] = wfdb.rdann(path, 'apn', shift_samps=True) # ラベル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'N', 'N', 'N', 'N', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'N', 'N', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n"
     ]
    }
   ],
   "source": [
    "# https://archive.physionet.org/physiobank/database/apnea-ecg/annotations.shtml\n",
    "# display(annotation.__dict__)\n",
    "display(len(records['ann_a01r'].sample))\n",
    "display(len(records['ann_a01r'].symbol))\n",
    "\n",
    "3108000 / 6000\n",
    "print(records['ann_a01r'].symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1015  -0.3446   0.23545  0.98   ]\n",
      " [-0.1025  -0.3455   0.2364   0.98   ]\n",
      " [-0.1035  -0.3464   0.23735  0.98   ]\n",
      " ...\n",
      " [-0.0642   0.0325  -0.1116   0.98   ]\n",
      " [-0.0526   0.0328  -0.11325  0.98   ]\n",
      " [-0.04095  0.0332  -0.1149   0.98   ]]\n"
     ]
    }
   ],
   "source": [
    "# 特徴量の抽出、学習用のデータ作成\n",
    "# 1 sample(6000個のデータ)毎に基本統計量を出してそれをInputに与える\n",
    "# 例) record.p_signal[0:6000], record.p_signal[6001:12001]で統計量を出す\n",
    "        \n",
    "def extract_feature(data):\n",
    "    return np.hstack([data.mean().values, data.std().values, data.max().values, data.min().values, (data.max() - data.min()).values])\n",
    "\n",
    "# train用\n",
    "# 'b01r', 'c01r', 'c02r' はSpO2が0%のため除外、'c01r~c03rのデータはAのラベルが無い'\n",
    "train_subjects = ['a01r', 'a02r', 'a04r', 'c03r']\n",
    "\n",
    "# test用\n",
    "test_subjects = ['a03r']\n",
    "\n",
    "data_array = []\n",
    "for subject in train_subjects:\n",
    "    # annotation分だけ繰り返す\n",
    "    ann_count = len(records['ann_'+subject].sample)\n",
    "    data = pd.DataFrame(records[subject].p_signal, columns=records[subject].sig_name, dtype='float')\n",
    "    data['SpO2'] = (data['SpO2'] / 100)\n",
    "    data = data.fillna(method='ffill') # 直前の値を使って欠損値埋める\n",
    "\n",
    "    start_idx = 0\n",
    "    end_idx = 6000\n",
    "    for n in range(0, ann_count):\n",
    "        data_array.append(data[start_idx:end_idx].to_numpy())\n",
    "        start_idx = end_idx + 1\n",
    "        end_idx = end_idx + 6000\n",
    "print(data_array[0])\n",
    "        \n",
    "test_data = []\n",
    "for subject in test_subjects:\n",
    "    ann_count = len(records['ann_'+subject].sample)\n",
    "    data = pd.DataFrame(records[subject].p_signal, columns=records[subject].sig_name, dtype='float')\n",
    "    data['SpO2'] = (data['SpO2'] / 100)\n",
    "    data = data.fillna(method='ffill') # 直前の値を使って欠損値埋める\n",
    "    start_idx = 0\n",
    "    end_idx = 6000\n",
    "    for n in range(0, ann_count):\n",
    "        test_data.append(data[start_idx:end_idx].to_numpy())\n",
    "        start_idx = end_idx + 1\n",
    "        end_idx = end_idx + 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1963\n",
      "24000\n",
      "[[-0.03055  0.03295 -0.11795  0.98   ]\n",
      " [-0.0318   0.03235 -0.11935  0.98   ]\n",
      " [-0.03305  0.03175 -0.12075  0.98   ]\n",
      " ...\n",
      " [-0.18845 -0.163    0.1757   0.97   ]\n",
      " [-0.1876  -0.1638   0.17755  0.97   ]\n",
      " [-0.18675 -0.1646   0.1795   0.97   ]]\n",
      "<class 'numpy.ndarray'>\n",
      "519\n"
     ]
    }
   ],
   "source": [
    "# 学習データ作成\n",
    "print(len(data_array))\n",
    "train_X = data_array\n",
    "\n",
    "print(train_X[0].size)\n",
    "print(train_X[1])\n",
    "print(type(train_X[1]))\n",
    "\n",
    "\n",
    "#train_X.shape\n",
    "\n",
    "# テストデータ作成\n",
    "print(len(test_data))\n",
    "test_X = test_data\n",
    "\n",
    "# test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1963"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NとAを1,0に変換する\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_data = []\n",
    "for subject in train_subjects:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(records['ann_' + subject].symbol)\n",
    "    labels = le.transform(records['ann_' + subject].symbol)\n",
    "    label_data = np.concatenate([label_data, labels], 0)\n",
    "\n",
    "# テスト用のラベル\n",
    "test_label = []\n",
    "for subject in test_subjects:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(records['ann_' + subject].symbol)\n",
    "    test_label = le.transform(records['ann_' + subject].symbol)\n",
    "    \n",
    "display(label_data)\n",
    "display(len(label_data))\n",
    "\n",
    "display(test_label)\n",
    "display(len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# モデルの作成\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(6000, 4000)),\n",
    "    keras.layers.Dense(100, activation='sigmoid'),\n",
    "    keras.layers.Dense(100, activation='sigmoid'),\n",
    "    keras.layers.Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.utils import plot_model\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, label_data,\n",
    "                    batch_size=128,   # 64,128みたいに2の倍数がよく使われるらしい\n",
    "                    epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
